{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2023-05-10T21:18:20.071542Z",
     "end_time": "2023-05-10T21:18:26.685050Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-10 21:18:24.677360: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-10 21:18:25.775178: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
      "2023-05-10 21:18:25.775391: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
      "2023-05-10 21:18:25.775404: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from model import LightningFullyConnected\n",
    "from verstack import LGBMTuner\n",
    "from lightgbm import LGBMClassifier\n",
    "import lightning as L\n",
    "from dataset import ParticleDataset\n",
    "from torch import optim\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import pickle\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([130000, 15]) torch.Size([130000])\n",
      "torch.Size([130000, 15]) torch.Size([130000, 160])\n"
     ]
    }
   ],
   "source": [
    "hidden_channels = 40\n",
    "decode_channels = 6\n",
    "hidden_layers = 5\n",
    "p_dropout = 0.1\n",
    "lr = 0.0003\n",
    "activation=nn.LeakyReLU\n",
    "final_activation=nn.Sigmoid\n",
    "batch_size=2500\n",
    "optimizer=optim.AdamW\n",
    "scheduler=optim.lr_scheduler.CosineAnnealingLR\n",
    "loss_fn=F.binary_cross_entropy\n",
    "in_channels=15\n",
    "out_channels=1\n",
    "use_wandb=True\n",
    "\n",
    "model1: LightningFullyConnected = LightningFullyConnected.load_from_checkpoint(\"../lightning_logs/version_0/checkpoints/epoch=49-step=2600.ckpt\")\n",
    "model2: LightningFullyConnected = LightningFullyConnected.load_from_checkpoint(\"../lightning_logs/version_1/checkpoints/epoch=30-step=1612.ckpt\")\n",
    "\n",
    "model1.to(\"cpu\")\n",
    "model2.to(\"cpu\")\n",
    "\n",
    "model1.eval()\n",
    "model2.eval()\n",
    "\n",
    "with open(\"../data/initial/lgbm_tuner.pickle\", \"rb\") as f:\n",
    "    tuner: LGBMTuner = pickle.load(f)\n",
    "\n",
    "data1_train, data1_val = ParticleDataset().split_data(0.8, seed=42)\n",
    "data2_train, data2_val = ParticleDataset(target=\"ALL\").split_data(0.8, seed=42)\n",
    "\n",
    "data1_val[:][0].to(\"cpu\")\n",
    "data2_val[:][0].to(\"cpu\")\n",
    "data1_train[:][0].to(\"cpu\")\n",
    "data2_train[:][0].to(\"cpu\")\n",
    "data1_val[:][1].to(\"cpu\")\n",
    "data2_val[:][1].to(\"cpu\")\n",
    "data1_train[:][1].to(\"cpu\")\n",
    "data2_train[:][1].to(\"cpu\")\n",
    "\n",
    "\n",
    "print(data1_train[:][0].shape, data1_train[:][1].shape)\n",
    "print(data2_train[:][0].shape, data2_train[:][1].shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-10T21:18:26.690868Z",
     "end_time": "2023-05-10T21:18:31.613614Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([130000])\n",
      "(130000,)\n",
      "[LightGBM] [Warning] lambda_l1 is set=1, reg_alpha=0.0 will be ignored. Current value: lambda_l1=1\n",
      "[LightGBM] [Warning] num_threads is set=6, n_jobs=-1 will be ignored. Current value: num_threads=6\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.9318657440733003, subsample=1.0 will be ignored. Current value: bagging_fraction=0.9318657440733003\n",
      "[LightGBM] [Warning] min_sum_hessian_in_leaf is set=0.289813314023732, min_child_weight=0.001 will be ignored. Current value: min_sum_hessian_in_leaf=0.289813314023732\n",
      "[LightGBM] [Warning] bagging_freq is set=1, subsample_freq=0 will be ignored. Current value: bagging_freq=1\n",
      "[LightGBM] [Warning] feature_fraction is set=0.8607121643836452, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.8607121643836452\n",
      "[LightGBM] [Warning] lambda_l2 is set=0.0, reg_lambda=0.0 will be ignored. Current value: lambda_l2=0.0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[0.9794997  0.06419704 0.9891587  ... 0.98900735 0.9035599  0.9952123 ].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[3], line 16\u001B[0m\n\u001B[1;32m     12\u001B[0m lgbm_big \u001B[38;5;241m=\u001B[39m LGBMClassifier(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mlgbm_hyper)\n\u001B[1;32m     13\u001B[0m lgbm\u001B[38;5;241m.\u001B[39mfit(data1_train[:][\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mnumpy(), data1_train[:][\u001B[38;5;241m1\u001B[39m]\u001B[38;5;241m.\u001B[39mnumpy())\n\u001B[0;32m---> 16\u001B[0m \u001B[43mlgbm_big\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata_train_big\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata1_train\u001B[49m\u001B[43m[\u001B[49m\u001B[43m:\u001B[49m\u001B[43m]\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     18\u001B[0m lgbm_proba \u001B[38;5;241m=\u001B[39m lgbm\u001B[38;5;241m.\u001B[39mpredict_proba(data1_val[:][\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mnumpy())[:, \u001B[38;5;241m1\u001B[39m]\n\u001B[1;32m     19\u001B[0m lgbm_big_proba \u001B[38;5;241m=\u001B[39m lgbm_big\u001B[38;5;241m.\u001B[39mpredict_proba()[:, \u001B[38;5;241m1\u001B[39m]\n",
      "File \u001B[0;32m~/Documents/Coding/GitHub/AppliedML2023/venv/lib/python3.10/site-packages/lightgbm/sklearn.py:967\u001B[0m, in \u001B[0;36mLGBMClassifier.fit\u001B[0;34m(self, X, y, sample_weight, init_score, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks, init_model)\u001B[0m\n\u001B[1;32m    964\u001B[0m         \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    965\u001B[0m             valid_sets[i] \u001B[38;5;241m=\u001B[39m (valid_x, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_le\u001B[38;5;241m.\u001B[39mtransform(valid_y))\n\u001B[0;32m--> 967\u001B[0m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m_y\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msample_weight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43msample_weight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minit_score\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minit_score\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43meval_set\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvalid_sets\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    968\u001B[0m \u001B[43m            \u001B[49m\u001B[43meval_names\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43meval_names\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43meval_sample_weight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43meval_sample_weight\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    969\u001B[0m \u001B[43m            \u001B[49m\u001B[43meval_class_weight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43meval_class_weight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43meval_init_score\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43meval_init_score\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    970\u001B[0m \u001B[43m            \u001B[49m\u001B[43meval_metric\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43meval_metric\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mearly_stopping_rounds\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mearly_stopping_rounds\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    971\u001B[0m \u001B[43m            \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mverbose\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfeature_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfeature_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcategorical_feature\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcategorical_feature\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    972\u001B[0m \u001B[43m            \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcallbacks\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minit_model\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minit_model\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    973\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\n",
      "File \u001B[0;32m~/Documents/Coding/GitHub/AppliedML2023/venv/lib/python3.10/site-packages/lightgbm/sklearn.py:658\u001B[0m, in \u001B[0;36mLGBMModel.fit\u001B[0;34m(self, X, y, sample_weight, init_score, group, eval_set, eval_names, eval_sample_weight, eval_class_weight, eval_init_score, eval_group, eval_metric, early_stopping_rounds, verbose, feature_name, categorical_feature, callbacks, init_model)\u001B[0m\n\u001B[1;32m    655\u001B[0m params[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmetric\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m [metric \u001B[38;5;28;01mfor\u001B[39;00m metric \u001B[38;5;129;01min\u001B[39;00m params[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmetric\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;28;01mif\u001B[39;00m metric \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m]\n\u001B[1;32m    657\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(X, (pd_DataFrame, dt_DataTable)):\n\u001B[0;32m--> 658\u001B[0m     _X, _y \u001B[38;5;241m=\u001B[39m \u001B[43m_LGBMCheckXY\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maccept_sparse\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mforce_all_finite\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mensure_min_samples\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m    659\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m sample_weight \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    660\u001B[0m         sample_weight \u001B[38;5;241m=\u001B[39m _LGBMCheckSampleWeight(sample_weight, _X)\n",
      "File \u001B[0;32m~/Documents/Coding/GitHub/AppliedML2023/venv/lib/python3.10/site-packages/sklearn/utils/validation.py:1074\u001B[0m, in \u001B[0;36mcheck_X_y\u001B[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001B[0m\n\u001B[1;32m   1069\u001B[0m         estimator_name \u001B[38;5;241m=\u001B[39m _check_estimator_name(estimator)\n\u001B[1;32m   1070\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m   1071\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mestimator_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m requires y to be passed, but the target y is None\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1072\u001B[0m     )\n\u001B[0;32m-> 1074\u001B[0m X \u001B[38;5;241m=\u001B[39m \u001B[43mcheck_array\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1075\u001B[0m \u001B[43m    \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1076\u001B[0m \u001B[43m    \u001B[49m\u001B[43maccept_sparse\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maccept_sparse\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1077\u001B[0m \u001B[43m    \u001B[49m\u001B[43maccept_large_sparse\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43maccept_large_sparse\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1078\u001B[0m \u001B[43m    \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1079\u001B[0m \u001B[43m    \u001B[49m\u001B[43morder\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43morder\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1080\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcopy\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcopy\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1081\u001B[0m \u001B[43m    \u001B[49m\u001B[43mforce_all_finite\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mforce_all_finite\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1082\u001B[0m \u001B[43m    \u001B[49m\u001B[43mensure_2d\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mensure_2d\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1083\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_nd\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mallow_nd\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1084\u001B[0m \u001B[43m    \u001B[49m\u001B[43mensure_min_samples\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mensure_min_samples\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1085\u001B[0m \u001B[43m    \u001B[49m\u001B[43mensure_min_features\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mensure_min_features\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1086\u001B[0m \u001B[43m    \u001B[49m\u001B[43mestimator\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mestimator\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1087\u001B[0m \u001B[43m    \u001B[49m\u001B[43minput_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mX\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1088\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1090\u001B[0m y \u001B[38;5;241m=\u001B[39m _check_y(y, multi_output\u001B[38;5;241m=\u001B[39mmulti_output, y_numeric\u001B[38;5;241m=\u001B[39my_numeric, estimator\u001B[38;5;241m=\u001B[39mestimator)\n\u001B[1;32m   1092\u001B[0m check_consistent_length(X, y)\n",
      "File \u001B[0;32m~/Documents/Coding/GitHub/AppliedML2023/venv/lib/python3.10/site-packages/sklearn/utils/validation.py:879\u001B[0m, in \u001B[0;36mcheck_array\u001B[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001B[0m\n\u001B[1;32m    877\u001B[0m     \u001B[38;5;66;03m# If input is 1D raise error\u001B[39;00m\n\u001B[1;32m    878\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m array\u001B[38;5;241m.\u001B[39mndim \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m--> 879\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    880\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mExpected 2D array, got 1D array instead:\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124marray=\u001B[39m\u001B[38;5;132;01m{}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    881\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mReshape your data either using array.reshape(-1, 1) if \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    882\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124myour data has a single feature or array.reshape(1, -1) \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    883\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mif it contains a single sample.\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mformat(array)\n\u001B[1;32m    884\u001B[0m         )\n\u001B[1;32m    886\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m dtype_numeric \u001B[38;5;129;01mand\u001B[39;00m array\u001B[38;5;241m.\u001B[39mdtype\u001B[38;5;241m.\u001B[39mkind \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mUSV\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m    887\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    888\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdtype=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mnumeric\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m is not compatible with arrays of bytes/strings.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    889\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mConvert your data to numeric values explicitly instead.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    890\u001B[0m     )\n",
      "\u001B[0;31mValueError\u001B[0m: Expected 2D array, got 1D array instead:\narray=[0.9794997  0.06419704 0.9891587  ... 0.98900735 0.9035599  0.9952123 ].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "lgbm_hyper = {'task': 'train', 'learning_rate': 0.04, 'num_leaves': 166, 'feature_fraction': 0.8607121643836452, 'bagging_fraction': 0.9318657440733003, 'bagging_freq': 1, 'max_depth': -1, 'verbosity': -1, 'lambda_l1': 1, 'lambda_l2': 0.0, 'min_split_gain': 0.0, 'zero_as_missing': False, 'max_bin': 255, 'min_data_in_bin': 3, 'random_state': 42, 'device_type': 'cpu', 'num_classes': 1, 'objective': 'binary', 'metric': 'binary_logloss', 'num_threads': 6, 'min_sum_hessian_in_leaf': 0.289813314023732, 'num_iterations': 313}\n",
    "\n",
    "data_train_big = model2(data1_train[:][0])\n",
    "print(data_train_big.shape)\n",
    "data_train_big = data_train_big.detach().numpy()\n",
    "\n",
    "data_val_big = model2(data1_val[:][0])\n",
    "data_val_big = data_val_big.detach().numpy()\n",
    "print(data_train_big.shape)\n",
    "\n",
    "lgbm = LGBMClassifier(**lgbm_hyper)\n",
    "lgbm_big = LGBMClassifier(**lgbm_hyper)\n",
    "lgbm.fit(data1_train[:][0].numpy(), data1_train[:][1].numpy())\n",
    "\n",
    "\n",
    "lgbm_big.fit(data_train_big, data1_train[:][1])\n",
    "\n",
    "lgbm_proba = lgbm.predict_proba(data1_val[:][0].numpy())[:, 1]\n",
    "lgbm_big_proba = lgbm_big.predict_proba()[:, 1]\n",
    "nn_proba = model1(data1_val[:][0])\n",
    "nn_proba = nn_proba.detach().numpy()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-10T20:58:40.801500Z",
     "end_time": "2023-05-10T20:58:45.100463Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "val_target = data1_val[:][1]\n",
    "print(val_target)\n",
    "print(lgbm_proba)\n",
    "print(lgbm_big)\n",
    "print(nn_proba)\n",
    "\n",
    "plt.hist(lgbm_proba[val_target == 0], bins=\"auto\", label=\"lgbm not electron\", color=\"b\", histtype=\"step\")\n",
    "plt.hist(lgbm_proba[val_target == 1], bins=\"auto\", label=\"lgbm electron\", color=\"r\", histtype=\"step\")\n",
    "plt.xlabel(\"lgbm prob\")\n",
    "plt.ylabel(\"obs\")\n",
    "plt.title(\"LGBM\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.hist(lgbm_big_proba[val_target == 0], bins=\"auto\", label=\"lgbm big not electron\", color=\"b\", histtype=\"step\")\n",
    "plt.hist(lgbm_big_proba[val_target == 1], bins=\"auto\", label=\"lgbm big electron\", color=\"r\", histtype=\"step\")\n",
    "plt.xlabel(\"lgbm prob\")\n",
    "plt.ylabel(\"obs\")\n",
    "plt.title(\"LGBM\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.hist(nn_proba[val_target == 0], bins=\"auto\", label=\"nn not electron\", color=\"b\", histtype=\"step\")\n",
    "plt.hist(nn_proba[val_target == 1], bins=\"auto\", label=\"nn electron\", color=\"r\", histtype=\"step\")\n",
    "plt.xlabel(\"nn prob\")\n",
    "plt.ylabel(\"obs\")\n",
    "plt.title(\"Neural network scores\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.hist2d(nn_proba, lgbm_proba, label=\"all\", bins=(10, 10), range=((0.98, 1.0), (0.98, 1.0)))\n",
    "plt.colorbar()\n",
    "plt.xlabel(\"nn probabilities\")\n",
    "plt.ylabel(\"lgbm probabilities\")\n",
    "plt.title(\"nn vs. lgbm\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "plt.hist2d(nn_proba, lgbm_proba, label=\"all\", bins=(10, 10), range=((0.0, 0.02), (0.0, 0.02)))\n",
    "plt.colorbar()\n",
    "plt.xlabel(\"nn probabilities\")\n",
    "plt.ylabel(\"lgbm probabilities\")\n",
    "plt.title(\"nn vs. lgbm\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-10T21:03:01.011175Z",
     "end_time": "2023-05-10T21:03:02.080765Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
